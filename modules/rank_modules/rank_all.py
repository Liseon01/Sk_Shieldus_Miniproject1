# rank_all.py

from rank_trivago import get_trivago_destinations
from rank_yanolja import get_yanolja_popular_destinations_selenium
from rank_yeogi import get_yeogi_keywords
from rank_agoda import scrape_korean_destinations_headless

import pandas as pd


def crawl_all_sources():
    """
    ëª¨ë“  ì‚¬ì´íŠ¸ì˜ ì¸ê¸° ì—¬í–‰ì§€ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜.
    """
    results = {}

    try:
        print("ğŸš€ Trivago í¬ë¡¤ë§ ì¤‘...")
        results["Trivago"] = get_trivago_destinations()
    except Exception as e:
        print(f"âŒ Trivago ì˜¤ë¥˜: {e}")
        results["Trivago"] = []

    try:
        print("ğŸš€ ì•¼ë†€ì í¬ë¡¤ë§ ì¤‘...")
        results["Yanolja"] = get_yanolja_popular_destinations_selenium()
    except Exception as e:
        print(f"âŒ Yanolja ì˜¤ë¥˜: {e}")
        results["Yanolja"] = []

    try:
        print("ğŸš€ ì—¬ê¸°ì–´ë•Œ í¬ë¡¤ë§ ì¤‘...")
        results["Yeogi"] = get_yeogi_keywords()
    except Exception as e:
        print(f"âŒ Yeogi ì˜¤ë¥˜: {e}")
        results["Yeogi"] = []

    try:
        print("ğŸš€ Agoda í¬ë¡¤ë§ ì¤‘...")
        results["Agoda"] = scrape_korean_destinations_headless()
    except Exception as e:
        print(f"âŒ Agoda ì˜¤ë¥˜: {e}")
        results["Agoda"] = []

    return results


def print_results(results):
    """
    í¬ë¡¤ë§ ê²°ê³¼ë¥¼ ì½˜ì†”ì— ì¶œë ¥.
    """
    for source, items in results.items():
        print(f"\nğŸ“Œ [{source}] ì¸ê¸° ì—¬í–‰ì§€ ëª©ë¡")
        if not items:
            print("  (ë°ì´í„° ì—†ìŒ)")
            continue
        for i, item in enumerate(items, 1):
            print(f"{i}. {item}")


def save_to_csv(results, filename="rank_all_combined.csv"):
    """
    í¬ë¡¤ë§ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥.
    """
    rows = []
    for source, items in results.items():
        for rank, region in enumerate(items, 1):
            rows.append([source, rank, region])

    df = pd.DataFrame(rows, columns=["Source", "Rank", "Region"])
    df.to_csv(filename, index=False, encoding="utf-8-sig")
    print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {filename}")


if __name__ == "__main__":
    all_results = crawl_all_sources()
    print_results(all_results)
    save_to_csv(all_results)
